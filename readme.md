# Wish.com Product Rating Prediction

So in this assignment, you will be working with a tabular dataset. The dataset is not clean, and you will need some preprocessing depending on the models of your choice. The dataset is the wish.com product dataset. We collected the data combined with some available data. Some nosies are added to the dataset. The goal is to predict the product ratings given the other features known for a product on Wish.com. Ratings are in categories from 1 to 5. For one product, the higher the rating is, the more the customers like the product. In this way, when you have a new product to be put on wish.com, you can estimate how likely people will like your product, without actually listing out there. Also, by doing this, it helps us to understand under what certain conditions that a product will be highly rated, as a way to understand the customer base of the wish.com.

You are encouraged to use the Google Colab environment for this assignment to run your experiments through Jupiter Notebook.



### Steps:
‚úîÔ∏è Meme competition [optional]:
Include/find a MEME that you liked related to data science/data mining/machine learning. You can upload yours here.

‚úîÔ∏è Problem Formulation:
Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?
(You can put your answers in markdown format in your notebook - Text Cell)

‚úîÔ∏è Document your code:
Put detailed comment on each line of the code to show your understanding of the your code. Also describe: What is the experimental protocol used and how was it carried out? What preprocessing steps are used?
(You can put your answers in markdown format in your notebook - Text Cell)

‚úîÔ∏è Model Tuning and Documentation:
Now based on the template, try to improve the model's performance on the public leaderboard by following the data science life-cycle for tuning. You can try different features, different hyperparameters/configurations of the model, and even a different model. For each trial, document the reason why you want to make the certain change and the expected outcome, before running the code. Record the observed performance and your thought on it. The final result is not important, but the process is. Documentation of your thought process is very important, since most people forgot why they test certain model/hyperparameter after they got the result (it takes time). It also helps a lot when you got stuck. You can organize the notebook by listing


You have to tune at least 5 times. All the tried solutions should be different (e.g. different feature sets/different preprocessing). Requirements:

- Tried decision tree model with at least 2 different configurations/hyper-parameters
- Tried SVM model with at least 2 different configurations/hyper-parameters
- Tried Naive Bayesian model.

### Answer the questions below (briefly):

üåà Why Data Mining is a misnomer? What is another preferred name?

üåà What is the general knowledge discovery process? What is the difference between a data engineer and data scientist/AI engineer?

üåà In data mining, what is the difference between prediction and categorization?

üåà Why data science/machine learning is a bad idea in the context of information security?

üåà What is CIA principle and how can we use it to access the security/privacy aspect of the AI system/pipelines?
